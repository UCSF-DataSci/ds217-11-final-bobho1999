{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "26b3d469",
   "metadata": {},
   "source": [
    "# Q2: Data Cleaning\n",
    "\n",
    "**Phase 3:** Data Cleaning & Preprocessing  \n",
    "**Points: 9 points**\n",
    "\n",
    "**Focus:** Handle missing data, outliers, validate data types, remove duplicates.\n",
    "\n",
    "**Lecture Reference:** Lecture 11, Notebook 1 ([`11/demo/01_setup_exploration_cleaning.ipynb`](https://github.com/christopherseaman/datasci_217/blob/main/11/demo/01_setup_exploration_cleaning.ipynb)), Phase 3. Also see Lecture 05 (data cleaning).\n",
    "\n",
    "---\n",
    "\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a377e3f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "# Load data from Q1 (or directly from source)\n",
    "df = pd.read_csv('data/beach_sensors.csv')\n",
    "# If you saved cleaned data from Q1, you can load it:\n",
    "# df = pd.read_csv('output/q1_exploration.csv')  # This won't work - load original"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e6b0ea",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Objective\n",
    "\n",
    "Clean the dataset by handling missing data, outliers, validating data types, and removing duplicates.\n",
    "\n",
    "**Time Series Note:** For time series data, forward-fill (`ffill()`) is often appropriate for missing values since sensor readings are continuous. However, you may choose other strategies based on your analysis.\n",
    "\n",
    "---\n",
    "\n",
    "## Required Artifacts\n",
    "\n",
    "You must create exactly these 3 files in the `output/` directory:\n",
    "\n",
    "### 1. `output/q2_cleaned_data.csv`\n",
    "**Format:** CSV file\n",
    "**Content:** Cleaned dataset with same structure as original (same columns)\n",
    "**Requirements:**\n",
    "- Same columns as original dataset\n",
    "- Missing values handled (filled, dropped, or imputed)\n",
    "- Outliers handled (removed, capped, or transformed)\n",
    "- Data types validated and converted\n",
    "- Duplicates removed\n",
    "- **Sanity check:** Dataset should retain most rows after cleaning (at least 1,000 rows). If you're removing more than 50% of data, reconsider your strategy—imputation is usually preferable to dropping rows for this dataset.\n",
    "- **No index column** (save with `index=False`)\n",
    "\n",
    "### 2. `output/q2_cleaning_report.txt`\n",
    "**Format:** Plain text file\n",
    "**Content:** Detailed report of cleaning operations\n",
    "**Required information:**\n",
    "- Rows before cleaning: [number]\n",
    "- Missing data handling method: [description]\n",
    "  - Which columns had missing data\n",
    "  - Method used (drop, forward-fill, impute, etc.)\n",
    "  - Number of values handled\n",
    "- Outlier handling: [description]\n",
    "  - Detection method (IQR, z-scores, domain knowledge)\n",
    "  - Which columns had outliers\n",
    "  - Method used (remove, cap, transform)\n",
    "  - Number of outliers handled\n",
    "- Duplicates removed: [number]\n",
    "- Data type conversions: [list any conversions]\n",
    "- Rows after cleaning: [number]\n",
    "\n",
    "**Example format:**\n",
    "```\n",
    "DATA CLEANING REPORT\n",
    "====================\n",
    "\n",
    "Rows before cleaning: 50000\n",
    "\n",
    "Missing Data Handling:\n",
    "- Water Temperature: 2500 missing values (5.0%)\n",
    "  Method: Forward-fill (time series appropriate)\n",
    "  Result: All missing values filled\n",
    "  \n",
    "- Air Temperature: 1500 missing values (3.0%)\n",
    "  Method: Forward-fill, then median imputation for remaining\n",
    "  Result: All missing values filled\n",
    "\n",
    "Outlier Handling:\n",
    "- Water Temperature: Detected 500 outliers using IQR method (3×IQR)\n",
    "  Method: Capped at bounds [Q1 - 3×IQR, Q3 + 3×IQR]\n",
    "  Bounds: [-5.2, 35.8]\n",
    "  Result: 500 values capped\n",
    "\n",
    "Duplicates Removed: 0\n",
    "\n",
    "Data Type Conversions:\n",
    "- Measurement Timestamp: Converted to datetime64[ns]\n",
    "\n",
    "Rows after cleaning: 50000\n",
    "```\n",
    "\n",
    "### 3. `output/q2_rows_cleaned.txt`\n",
    "**Format:** Plain text file\n",
    "**Content:** Single integer number (total rows after cleaning)\n",
    "**Requirements:**\n",
    "- Only the number, no text, no labels\n",
    "- No whitespace before or after\n",
    "- Example: `50000`\n",
    "\n",
    "---\n",
    "\n",
    "## Requirements Checklist\n",
    "\n",
    "- [ ] Missing data handling strategy chosen and implemented\n",
    "- [ ] Outliers detected and handled (IQR method, z-scores, or domain knowledge)\n",
    "- [ ] Data types validated and converted\n",
    "- [ ] Duplicates identified and removed\n",
    "- [ ] Cleaning decisions documented in report\n",
    "- [ ] All 3 required artifacts saved with exact filenames\n",
    "\n",
    "---\n",
    "\n",
    "## Your Approach\n",
    "\n",
    "1. **Handle missing data** - Choose appropriate strategy (drop, forward-fill, impute) based on data characteristics\n",
    "2. **Detect and handle outliers** - Use IQR method or z-scores; decide whether to remove, cap, or transform\n",
    "3. **Validate data types** - Ensure numeric and datetime columns are properly typed\n",
    "4. **Remove duplicates**\n",
    "5. **Document and save** - Write detailed cleaning report explaining your decisions\n",
    "\n",
    "---\n",
    "\n",
    "## Decision Points\n",
    "\n",
    "- **Missing data:** Should you drop rows, impute values, or forward-fill? Consider: How much data is missing? Is it random or systematic? For time series, forward-fill is often appropriate.\n",
    "- **Outliers:** Are they errors or valid extreme values? Use IQR method or z-scores to detect, then decide: remove, cap, or transform. Document your reasoning.\n",
    "- **Data types:** Are numeric columns actually numeric? Are datetime columns properly formatted? Convert as needed.\n",
    "\n",
    "---\n",
    "\n",
    "## Checkpoint\n",
    "\n",
    "After Q2, you should have:\n",
    "- [ ] Missing data handled\n",
    "- [ ] Outliers addressed\n",
    "- [ ] Data types validated\n",
    "- [ ] Duplicates removed\n",
    "- [ ] All 3 artifacts saved: `q2_cleaned_data.csv`, `q2_cleaning_report.txt`, `q2_rows_cleaned.txt`\n",
    "\n",
    "---\n",
    "\n",
    "**Next:** Continue to `q3_data_wrangling.md` for Data Wrangling.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c6b6fcd",
   "metadata": {},
   "source": [
    "## Start "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b255bac2",
   "metadata": {},
   "source": [
    "### Missing Data Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "488a2395",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Station Name                    object\n",
       "Measurement Timestamp           object\n",
       "Air Temperature                float64\n",
       "Wet Bulb Temperature           float64\n",
       "Humidity                         int64\n",
       "Rain Intensity                 float64\n",
       "Interval Rain                  float64\n",
       "Total Rain                     float64\n",
       "Precipitation Type             float64\n",
       "Wind Direction                   int64\n",
       "Wind Speed                     float64\n",
       "Maximum Wind Speed             float64\n",
       "Barometric Pressure            float64\n",
       "Solar Radiation                  int64\n",
       "Heading                        float64\n",
       "Battery Life                   float64\n",
       "Measurement Timestamp Label     object\n",
       "Measurement ID                  object\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index data type: datetime64[ns]\n"
     ]
    }
   ],
   "source": [
    "# Check data type\n",
    "display(df.dtypes)\n",
    "\n",
    "# Convert Measurement timestamp to datetime and set as index\n",
    "df['Measurement Timestamp'] = pd.to_datetime(df['Measurement Timestamp'])\n",
    "df = df.set_index('Measurement Timestamp')\n",
    "\n",
    "# Verify datetime index\n",
    "print(\"Index data type:\", df.index.dtype)\n",
    "df = df.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc628832",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Data Analysis\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column</th>\n",
       "      <th>Type</th>\n",
       "      <th>Missing</th>\n",
       "      <th>Missing %</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Wet Bulb Temperature</td>\n",
       "      <td>float64</td>\n",
       "      <td>75926</td>\n",
       "      <td>38.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Rain Intensity</td>\n",
       "      <td>float64</td>\n",
       "      <td>75926</td>\n",
       "      <td>38.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Total Rain</td>\n",
       "      <td>float64</td>\n",
       "      <td>75926</td>\n",
       "      <td>38.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Precipitation Type</td>\n",
       "      <td>float64</td>\n",
       "      <td>75926</td>\n",
       "      <td>38.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Heading</td>\n",
       "      <td>float64</td>\n",
       "      <td>75926</td>\n",
       "      <td>38.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Barometric Pressure</td>\n",
       "      <td>float64</td>\n",
       "      <td>146</td>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Air Temperature</td>\n",
       "      <td>float64</td>\n",
       "      <td>75</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Column     Type  Missing  Missing %\n",
       "2   Wet Bulb Temperature  float64    75926      38.68\n",
       "4         Rain Intensity  float64    75926      38.68\n",
       "6             Total Rain  float64    75926      38.68\n",
       "7     Precipitation Type  float64    75926      38.68\n",
       "13               Heading  float64    75926      38.68\n",
       "11   Barometric Pressure  float64      146       0.07\n",
       "1        Air Temperature  float64       75       0.04"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows where ALL are missing: 75,926\n",
      "Rows where ANY is missing: 75,926\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'By Station:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Missing rows %</th>\n",
       "      <th>Complete rows %</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Station Name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>63rd Street Weather Station</th>\n",
       "      <td>NaN</td>\n",
       "      <td>41.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Foster Weather Station</th>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Oak Street Weather Station</th>\n",
       "      <td>NaN</td>\n",
       "      <td>58.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Missing rows %  Complete rows %\n",
       "Station Name                                                \n",
       "63rd Street Weather Station             NaN             41.5\n",
       "Foster Weather Station                100.0              NaN\n",
       "Oak Street Weather Station              NaN             58.5"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "By Date Range:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Missing rows</th>\n",
       "      <th>Complete rows</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Earliest measurement</td>\n",
       "      <td>2015-05-22 16:00:00</td>\n",
       "      <td>2015-04-25 09:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Latest measurement</td>\n",
       "      <td>2025-12-02 12:00:00</td>\n",
       "      <td>2025-12-02 12:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Count</td>\n",
       "      <td>75,926</td>\n",
       "      <td>120,345</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Metric         Missing rows        Complete rows\n",
       "0  Earliest measurement  2015-05-22 16:00:00  2015-04-25 09:00:00\n",
       "1    Latest measurement  2025-12-02 12:00:00  2025-12-02 12:00:00\n",
       "2                 Count               75,926              120,345"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing rows by date (top 10 dates):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>missing_count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Measurement Timestamp</th>\n",
       "      <th>Measurement Timestamp</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2023</th>\n",
       "      <th>1</th>\n",
       "      <td>743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022</th>\n",
       "      <th>7</th>\n",
       "      <td>743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019</th>\n",
       "      <th>8</th>\n",
       "      <td>742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020</th>\n",
       "      <th>10</th>\n",
       "      <td>742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">2025</th>\n",
       "      <th>7</th>\n",
       "      <td>741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">2022</th>\n",
       "      <th>1</th>\n",
       "      <td>739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019</th>\n",
       "      <th>1</th>\n",
       "      <td>739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025</th>\n",
       "      <th>10</th>\n",
       "      <td>738</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             missing_count\n",
       "Measurement Timestamp Measurement Timestamp               \n",
       "2023                  1                                743\n",
       "2022                  7                                743\n",
       "2019                  8                                742\n",
       "2020                  10                               742\n",
       "2025                  7                                741\n",
       "                      5                                740\n",
       "2022                  1                                739\n",
       "                      8                                739\n",
       "2019                  1                                739\n",
       "2025                  10                               738"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Station Name\n",
       "63rd Street Weather Station    49951\n",
       "Foster Weather Station         75926\n",
       "Oak Street Weather Station     70394\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Save info for later report\n",
    "rows_before_cleaning = len(df)\n",
    "\n",
    "# Handle Missing Data\n",
    "print(\"Missing Data Analysis\")\n",
    "\n",
    "# Detailed missing data analysis with data types for context\n",
    "missing_analysis = pd.DataFrame({\n",
    "    'Column': df.columns,\n",
    "    'Type': df.dtypes.astype(str).values,\n",
    "    'Missing': df.isnull().sum().values,\n",
    "    'Missing %': (df.isnull().sum() / len(df) * 100).round(2).values\n",
    "})\n",
    "missing_analysis = missing_analysis[missing_analysis['Missing'] > 0].sort_values('Missing', ascending=False)\n",
    "\n",
    "if len(missing_analysis) == 0:\n",
    "    print(\"No missing values found\")\n",
    "else:\n",
    "    display(missing_analysis)\n",
    "\n",
    "# Check if missing values occur in the same rows\n",
    "cols_with_same_missing = ['Wet Bulb Temperature', 'Rain Intensity', 'Total Rain', 'Precipitation Type', 'Heading']\n",
    "missing_mask = df[cols_with_same_missing].isnull()\n",
    "print(f\"Rows where ALL are missing: {missing_mask.all(axis=1).sum():,}\")\n",
    "print(f\"Rows where ANY is missing: {missing_mask.any(axis=1).sum():,}\")\n",
    "# If these numbers match, missingness is perfectly correlated\n",
    "\n",
    "# Investigate: What characterizes the rows with missing data?\n",
    "cols_available = [c for c in cols_with_same_missing if c in df.columns]\n",
    "missing_mask = df[cols_available].isnull()\n",
    "\n",
    "rows_with_missing = df[missing_mask.all(axis=1)]\n",
    "rows_complete = df[~missing_mask.any(axis=1)]\n",
    "\n",
    "# Check station distribution - is it one station's data?\n",
    "display(\"By Station:\")\n",
    "station_comparison = pd.DataFrame({\n",
    "    'Missing rows %': rows_with_missing['Station Name'].value_counts(normalize=True).round(3) * 100,\n",
    "    'Complete rows %': rows_complete['Station Name'].value_counts(normalize=True).round(3) * 100\n",
    "})\n",
    "display(station_comparison)\n",
    "\n",
    "# Check time distribution - are missing rows from a specific period?\n",
    "print(\"By Date Range:\")\n",
    "display(pd.DataFrame({\n",
    "    'Metric': ['Earliest measurement', 'Latest measurement', 'Count'],\n",
    "    'Missing rows': [\n",
    "        rows_with_missing.index.min(), \n",
    "        rows_with_missing.index.max(),\n",
    "        f\"{len(rows_with_missing):,}\"\n",
    "    ],\n",
    "    'Complete rows': [\n",
    "        rows_complete.index.min(), \n",
    "        rows_complete.index.max(),\n",
    "        f\"{len(rows_complete):,}\"\n",
    "    ]\n",
    "}))\n",
    "\n",
    "# Check if missing rows cluster on specific dates\n",
    "print(\"Missing rows by date (top 10 dates):\")\n",
    "missing_by_date = rows_with_missing.groupby([rows_with_missing.index.year, rows_with_missing.index.month]).size().sort_values(ascending=False)\n",
    "display(missing_by_date.head(10).to_frame('missing_count'))\n",
    "\n",
    "display(df.groupby('Station Name').size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e3d7f623",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape after dropping missing value: (120345, 17)\n",
      "No missing values found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5t/lfb7y4m975b78bly378zr4880000gn/T/ipykernel_32473/2617075055.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_no_missing['Air Temperature'] = df_no_missing.groupby('Station Name')['Air Temperature'].bfill()\n",
      "/var/folders/5t/lfb7y4m975b78bly378zr4880000gn/T/ipykernel_32473/2617075055.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_no_missing['Barometric Pressure'] = df_no_missing.groupby('Station Name')['Barometric Pressure'].bfill()\n"
     ]
    }
   ],
   "source": [
    "# Strategy for handling missing data\n",
    "# After investigation, I realized all the missing data from 'Foster Weather Station'.\n",
    "# Specifically, the station is missing values in key raining data such as total rain\n",
    "# and precipitation type. Since measurements can vary significantly between stations \n",
    "# due to microclimates or other local factors, I don't think it is a good idea to fill\n",
    "# the missing data using values from other weather station. Instead, I think it's best \n",
    "# that we drop the data from Foster Weather Station from the analysis.\n",
    "df_no_missing = df[df['Station Name'].isin(['63rd Street Weather Station', 'Oak Street Weather Station'])]\n",
    "# df_no_missing['Rain Intensity'] = df_no_missing.fillna(df_no_missing.groupby(df_no_missing.index))\n",
    "\n",
    "# For the remaining missing value in column Air Temperature and Barometric Pressure,\n",
    "# I tried to fill missing value using forward filling within each station. However, \n",
    "# the method failed because the missing value is at the start of the data. Therefore,\n",
    "# I use backword filling instead to fill the missing value while retaining the trend\n",
    "# and distribution.\n",
    "df_no_missing['Air Temperature'] = df_no_missing.groupby('Station Name')['Air Temperature'].bfill()\n",
    "df_no_missing['Barometric Pressure'] = df_no_missing.groupby('Station Name')['Barometric Pressure'].bfill()\n",
    "\n",
    "# Check dataset shape after dropping to ensure we are have enough data\n",
    "print(\"Data shape after dropping missing value:\", df_no_missing.shape)\n",
    "\n",
    "# Check if all missing values are filled\n",
    "missing_analysis = pd.DataFrame({\n",
    "    'Column': df_no_missing.columns,\n",
    "    'Type': df_no_missing.dtypes.astype(str).values,\n",
    "    'Missing': df_no_missing.isnull().sum().values,\n",
    "    'Missing %': (df_no_missing.isnull().sum() / len(df_no_missing) * 100).round(2).values\n",
    "})\n",
    "missing_analysis = missing_analysis[missing_analysis['Missing'] > 0].sort_values('Missing', ascending=False)\n",
    "\n",
    "if len(missing_analysis) == 0:\n",
    "    print(\"No missing values found\")\n",
    "else:\n",
    "    print(\"Failed to handle missing data\")\n",
    "    display(missing_analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32bdd74b",
   "metadata": {},
   "source": [
    "### Outlier Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "edecd4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adopted the 'detect_outliers_iqr' function from demo\n",
    "# Identify outliers using IQR method with Tukey fences\n",
    "def detect_outliers_iqr(df, column, iqr_multiplier=1.5):\n",
    "    \"\"\"\n",
    "    Detect outliers using the IQR (Interquartile Range) method.\n",
    "\n",
    "    This is the Tukey fence method, which is robust and doesn't assume\n",
    "    normal distribution. It's widely used in exploratory data analysis.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : DataFrame\n",
    "        The data\n",
    "    column : str\n",
    "        Column name to check for outliers\n",
    "    iqr_multiplier : float, default=1.5\n",
    "        Tukey fence multiplier:\n",
    "        - 1.5 = standard outlier detection (common choice)\n",
    "        - 3.0 = extreme outlier detection (more conservative)\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    tuple : (outliers DataFrame, lower_bound, upper_bound)\n",
    "    \"\"\"\n",
    "    Q1 = df[column].quantile(0.25)  # 25th percentile\n",
    "    Q3 = df[column].quantile(0.75)  # 75th percentile\n",
    "    IQR = Q3 - Q1  # Interquartile range (middle 50% of data)\n",
    "\n",
    "    # Tukey fences: standard statistical method for outlier detection\n",
    "    lower_bound = Q1 - iqr_multiplier * IQR\n",
    "    upper_bound = Q3 + iqr_multiplier * IQR\n",
    "\n",
    "    # Find values outside the fences\n",
    "    outliers = df[(df[column] < lower_bound) | (df[column] > upper_bound)]\n",
    "    return outliers, lower_bound, upper_bound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "917d61fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data outlier summary:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lower bound</th>\n",
       "      <th>Upper bound</th>\n",
       "      <th>Number of outliers</th>\n",
       "      <th>Outlier %</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Column Name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Air Temperature</th>\n",
       "      <td>-20.50</td>\n",
       "      <td>47.50</td>\n",
       "      <td>59</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wet Bulb Temperature</th>\n",
       "      <td>-20.10</td>\n",
       "      <td>41.50</td>\n",
       "      <td>88</td>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Humidity</th>\n",
       "      <td>24.50</td>\n",
       "      <td>116.50</td>\n",
       "      <td>160</td>\n",
       "      <td>0.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rain Intensity</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4243</td>\n",
       "      <td>3.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Interval Rain</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>9383</td>\n",
       "      <td>7.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total Rain</th>\n",
       "      <td>-259.00</td>\n",
       "      <td>476.20</td>\n",
       "      <td>9507</td>\n",
       "      <td>7.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precipitation Type</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8414</td>\n",
       "      <td>6.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wind Direction</th>\n",
       "      <td>-239.50</td>\n",
       "      <td>580.50</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wind Speed</th>\n",
       "      <td>-2.15</td>\n",
       "      <td>7.05</td>\n",
       "      <td>3945</td>\n",
       "      <td>3.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Maximum Wind Speed</th>\n",
       "      <td>-2.90</td>\n",
       "      <td>11.50</td>\n",
       "      <td>3207</td>\n",
       "      <td>2.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Barometric Pressure</th>\n",
       "      <td>978.00</td>\n",
       "      <td>1011.60</td>\n",
       "      <td>2796</td>\n",
       "      <td>2.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Solar Radiation</th>\n",
       "      <td>-257.00</td>\n",
       "      <td>431.00</td>\n",
       "      <td>15863</td>\n",
       "      <td>13.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Heading</th>\n",
       "      <td>339.50</td>\n",
       "      <td>367.50</td>\n",
       "      <td>27175</td>\n",
       "      <td>22.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Battery Life</th>\n",
       "      <td>11.75</td>\n",
       "      <td>12.15</td>\n",
       "      <td>3356</td>\n",
       "      <td>2.79</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Lower bound  Upper bound  Number of outliers  Outlier %\n",
       "Column Name                                                                  \n",
       "Air Temperature            -20.50        47.50                  59       0.05\n",
       "Wet Bulb Temperature       -20.10        41.50                  88       0.07\n",
       "Humidity                    24.50       116.50                 160       0.13\n",
       "Rain Intensity               0.00         0.00                4243       3.53\n",
       "Interval Rain                0.00         0.00                9383       7.80\n",
       "Total Rain                -259.00       476.20                9507       7.90\n",
       "Precipitation Type           0.00         0.00                8414       6.99\n",
       "Wind Direction            -239.50       580.50                   0       0.00\n",
       "Wind Speed                  -2.15         7.05                3945       3.28\n",
       "Maximum Wind Speed          -2.90        11.50                3207       2.66\n",
       "Barometric Pressure        978.00      1011.60                2796       2.32\n",
       "Solar Radiation           -257.00       431.00               15863      13.18\n",
       "Heading                    339.50       367.50               27175      22.58\n",
       "Battery Life                11.75        12.15                3356       2.79"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Select numeric columns only\n",
    "numeric_cols = df_no_missing.select_dtypes(include=[np.number]).columns.tolist()\n",
    "\n",
    "# Check outliers for all numerical columns using IQR method \n",
    "# for a general understanding\n",
    "outlier_df = pd.DataFrame(columns= ['Column Name', 'Lower bound', 'Upper bound', 'Number of outliers', 'Outlier %'])\n",
    "for col in numeric_cols:\n",
    "    col_outliers, col_lower, col_upper = detect_outliers_iqr(df_no_missing, col)\n",
    "    outlier_df.loc[len(outlier_df)] = [col, col_lower, col_upper, len(col_outliers), round((len(col_outliers)/len(df_no_missing)*100),2)]\n",
    "\n",
    "outlier_df = outlier_df.set_index('Column Name')\n",
    "print(\"Data outlier summary:\")\n",
    "display(outlier_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "780431e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Handling Outliers ===\n",
      "Original shape: 120,345 rows × 19 columns\n",
      "Shape after outlier handling: 103,559 rows × 19 columns\n"
     ]
    }
   ],
   "source": [
    "# Handle outliers based on domain knowledge\n",
    "print(\"=== Handling Outliers ===\")\n",
    "\n",
    "# Instead of dropping rows, we'll create an EXCLUSION FLAG\n",
    "# This approach is better because:\n",
    "# 1. Preserves original data for analysis\n",
    "# 2. Transparent about what's being filtered\n",
    "# 3. Can toggle exclusions on/off\n",
    "# 4. Easy to see WHY a row was excluded\n",
    "\n",
    "df_clean = df_no_missing.copy()\n",
    "df_clean['exclude'] = False  # Start with no exclusions\n",
    "df_clean['exclude_reason'] = ''  # Track why rows are excluded\n",
    "\n",
    "print(f\"Original shape: {df_clean.shape[0]:,} rows × {df_clean.shape[1]} columns\")\n",
    "\n",
    "# Define some data quality thresholds based on domain knowledge\n",
    "MIN_HUMIDITY = 0  # Humidity cannot be negative\n",
    "# MIN_RAIN_INTENSITY = 0  # Rain cannot be negative\n",
    "# MIN_INTERVAL_RAIN = 0  # Rain cannot be negative\n",
    "# MIN_TOTAL_RAIN = 0  # Rain cannot be negative\n",
    "MIN_WIND_SPEED = 0\n",
    "MAX_WIND_SPEED = 103.3 # Maximum wind speed ever recorded in the US\n",
    "MIN_BAROMETRIC_PRESSURE = 870 # The lowest non-tornadic pressure ever recorded\n",
    "MAX_BAROMETRIC_PRESSURE = 1083.8 #  The highest sea-level air pressure ever officially recorded on Earth was 1083.8 hPa in Agata, Siberia, in 1968. \n",
    "MIN_SOLAR_RADIATION = 0\n",
    "MIN_HEADING = 0\n",
    "MAX_HEADING = 359\n",
    "EXPECTED_TYPE = [0, 40, 60, 70]\n",
    "\n",
    "# Flag exclusions with reasons (using bitwise OR to accumulate flags)\n",
    "def flag_exclusion(df, condition, reason):\n",
    "    \"\"\"Flag rows for exclusion and record the reason.\"\"\"\n",
    "    mask = condition\n",
    "    df.loc[mask & ~df['exclude'], 'exclude_reason'] = reason  # First reason wins\n",
    "    df.loc[mask, 'exclude'] = True\n",
    "    return mask.sum()\n",
    "\n",
    "# Apply exclusion rules, either with IQR method or domain knowledge\n",
    "n_outlier_air_temp = flag_exclusion(df_clean, ~df_clean['Air Temperature'].between(outlier_df.loc['Air Temperature', 'Lower bound'], outlier_df.loc['Air Temperature', 'Upper bound']), 'Air Temperature > or < 1.5*IQR')\n",
    "n_outlier_wetbulb_temp = flag_exclusion(df_clean, ~df_clean['Wet Bulb Temperature'].between(outlier_df.loc['Wet Bulb Temperature', 'Lower bound'], outlier_df.loc['Wet Bulb Temperature', 'Upper bound']), 'Wet bulb Temp > or < 1.5*IQR')\n",
    "n_outlier_humidity = flag_exclusion(df_clean, ~df_clean['Humidity'].between(outlier_df.loc['Humidity', 'Lower bound'], outlier_df.loc['Humidity', 'Upper bound']), 'Humidity > or < 1.5*IQR')\n",
    "# n_outlier_rain = flag_exclusion(df_clean, ~df_clean['Total Rain'].between(outlier_df.loc['Total Rain', 'Lower bound'], outlier_df.loc['Total Rain', 'Upper bound']), 'Humidity > or < 1.5*IQR')\n",
    "n_outlier_wind = flag_exclusion(df_clean, ~df_clean['Wind Speed'].between(MIN_WIND_SPEED, MAX_WIND_SPEED), 'negative_wind_speed or > max_wind_speed')\n",
    "n_outlier_max_wind = flag_exclusion(df_clean, ~df_clean['Maximum Wind Speed'].between(MIN_WIND_SPEED, MAX_WIND_SPEED), 'negative_wind_speed or > max_wind_speed')\n",
    "n_outlier_pressure = flag_exclusion(df_clean, ~df_clean['Barometric Pressure'].between(MIN_BAROMETRIC_PRESSURE, MAX_BAROMETRIC_PRESSURE), 'unreasonable_pressure')\n",
    "n_outlier_solar = flag_exclusion(df_clean, df_clean['Solar Radiation'] < 0, 'negative_solar_radiation')\n",
    "n_outlier_battery = flag_exclusion(df_clean, ~df_clean['Battery Life'].between(outlier_df.loc['Battery Life', 'Lower bound'], outlier_df.loc['Battery Life', 'Upper bound']), 'Humidity > or < 1.5*IQR')\n",
    "\n",
    "# display(df_clean[ df_clean['Solar Radiation'] < -6][['Solar Radiation', 'exclude']].head(10))\n",
    "# print(n_outlier_solar)\n",
    "# Move forward with cleaned data only\n",
    "df_valid = df_clean[~df_clean['exclude']]\n",
    "print(f\"Shape after outlier handling: {df_valid.shape[0]:,} rows × {df_valid.shape[1]} columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e90d0c08",
   "metadata": {},
   "source": [
    "### Duplicate Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "437a6dc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Duplicate Detection ===\n",
      "Completely duplicate rows: 0\n",
      "Shape after duplicate handling: 103,559 rows × 19 columns\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Total rows</td>\n",
       "      <td>120,345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Rows to keep</td>\n",
       "      <td>103,559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rows excluded</td>\n",
       "      <td>16,786 (13.95%)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Metric            Value\n",
       "0     Total rows          120,345\n",
       "1   Rows to keep          103,559\n",
       "2  Rows excluded  16,786 (13.95%)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check for duplicate rows\n",
    "print(\"=== Duplicate Detection ===\")\n",
    "\n",
    "# Check for completely duplicate rows\n",
    "# n_duplicates = df_clean.duplicated().sum()\n",
    "# print(f\"Completely duplicate rows: {n_duplicates:,}\")\n",
    "\n",
    "# Check for completely duplicate rows and mark duplicates\n",
    "duplicates = df_clean.duplicated(keep='first')\n",
    "n_duplicates = flag_exclusion(df_clean, duplicates, 'duplicate')\n",
    "print(f\"Completely duplicate rows: {n_duplicates:,}\")\n",
    "\n",
    "# Move forward with cleaned data only\n",
    "df_valid = df_clean[~df_clean['exclude']]\n",
    "print(f\"Shape after duplicate handling: {df_valid.shape[0]:,} rows × {df_valid.shape[1]} columns\")\n",
    "\n",
    "# Overall summary\n",
    "n_excluded = df_clean['exclude'].sum()\n",
    "display(pd.DataFrame({\n",
    "    'Metric': ['Total rows', 'Rows to keep', 'Rows excluded'],\n",
    "    'Value': [\n",
    "        f\"{len(df_clean):,}\",\n",
    "        f\"{(~df_clean['exclude']).sum():,}\",\n",
    "        f\"{n_excluded:,} ({n_excluded/len(df_clean)*100:.2f}%)\"\n",
    "    ]\n",
    "}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "457b0084",
   "metadata": {},
   "source": [
    "### Data Type Validation and Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a8c215a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure numeric columns are proper types\n",
    "numeric_cols = ['Air Temperature', 'Wet Bulb Temperature', 'Humidity', 'Rain Intensity', \n",
    "                'Interval Rain', 'Total Rain', 'Wind Direction', 'Wind Speed',\n",
    "                'Maximum Wind Speed', 'Barometric Pressure', 'Solar Radiation',\n",
    "                'Heading']\n",
    "for col in numeric_cols:\n",
    "    df_clean[col] = pd.to_numeric(df_clean[col], errors='coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "590777cb",
   "metadata": {},
   "source": [
    "### Cleaning Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8c9595d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save cleaned data\n",
    "df_valid.to_csv('output/q2_cleaned_data.csv')\n",
    "\n",
    "# Write cleaning report\n",
    "with open('output/q2_cleaning_report.txt', 'w') as f:\n",
    "    f.write('DATA CLEANING REPORT\\n')\n",
    "    f.write('====================\\n')\n",
    "    f.write(f'\\nRows before cleaning: {rows_before_cleaning}\\n')\n",
    "\n",
    "    f.write(f'\\nMissing Data Handling:\\n')\n",
    "\n",
    "    f.write(f'\\nOutlier Handling:\\n')\n",
    "    \n",
    "    f.write(f'\\nDuplicates Removed: {n_duplicates}\\n')\n",
    "\n",
    "    f.write(f'\\nData Type Conversions:\\n')\n",
    "    f.write(f'- Measurement Timestamp: Converted to {df_valid.index.dtype}')\n",
    "\n",
    "    f.write(f'\\nRows after cleaning: {len(df_valid)}\\n')\n",
    "# Rows cleaned\n",
    "with open('output/q2_rows_cleaned.txt', 'w') as f:\n",
    "    f.write(f\"{len(df_valid)}\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": ".venv (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
